{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6508e74f-ab26-4a93-b12d-54d1051c0b3a",
   "metadata": {},
   "source": [
    "## Installation and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dafe9ae-f5e7-486e-aeaa-52d42d0a8246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tkmacosx in /Users/zunyang/anaconda3/lib/python3.11/site-packages (1.0.5)\n",
      "Requirement already satisfied: colour in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from tkmacosx) (0.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install tkmacosx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82f4070d-79cd-45f5-af2a-cf780997b0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: easydict in /Users/zunyang/anaconda3/lib/python3.11/site-packages (1.13)\n",
      "Requirement already satisfied: numpy in /Users/zunyang/anaconda3/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: tqdm in /Users/zunyang/anaconda3/lib/python3.11/site-packages (4.65.0)\n",
      "Requirement already satisfied: torchvision in /Users/zunyang/anaconda3/lib/python3.11/site-packages (0.18.0)\n",
      "Requirement already satisfied: numpy in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.3.0 in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from torchvision) (2.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: filelock in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from torch==2.3.0->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from torch==2.3.0->torchvision) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from torch==2.3.0->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from torch==2.3.0->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from torch==2.3.0->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from torch==2.3.0->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from jinja2->torch==2.3.0->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: torch in /Users/zunyang/anaconda3/lib/python3.11/site-packages (2.3.0)\n",
      "Requirement already satisfied: filelock in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: opencv-python in /Users/zunyang/anaconda3/lib/python3.11/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /Users/zunyang/anaconda3/lib/python3.11/site-packages (10.2.0)\n",
      "Requirement already satisfied: tensorboardX in /Users/zunyang/anaconda3/lib/python3.11/site-packages (2.6.2.2)\n",
      "Requirement already satisfied: numpy in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from tensorboardX) (1.26.4)\n",
      "Requirement already satisfied: packaging in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from tensorboardX) (23.1)\n",
      "Requirement already satisfied: protobuf>=3.20 in /Users/zunyang/anaconda3/lib/python3.11/site-packages (from tensorboardX) (3.20.3)\n"
     ]
    }
   ],
   "source": [
    "# for antispoofing module\n",
    "!pip install easydict\n",
    "!pip install numpy\n",
    "!pip install tqdm\n",
    "!pip install torchvision\n",
    "!pip install torch\n",
    "!pip install opencv-python\n",
    "!pip install Pillow\n",
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c34637f-c074-476d-90f9-1676ae6651df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.models import load_model\n",
    "import tkinter as tk\n",
    "from tkmacosx import Button\n",
    "from tkinter import messagebox\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    " # for recording attendance\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# for antispoof\n",
    "import sys\n",
    "\n",
    "# Assuming 'anti_spoof_src' directory is in the same directory as the notebook\n",
    "project_dir = os.path.abspath('antispoofing')\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "    \n",
    "from antispoofing.test import test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b568f4-bba5-4cb3-9046-ebcad95f67d7",
   "metadata": {},
   "source": [
    "## Loading L1Dist and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "574ed9df-8607-43dd-ae54-cb93c8eb1cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese L1 Distance class\n",
    "# pass in keras layer as param\n",
    "class L1Dist(Layer):\n",
    "    # Init method - inheritance\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "    # input_embedding is anchor, validaation_embedding is either positive or negative\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(tf.convert_to_tensor(input_embedding) - tf.convert_to_tensor(validation_embedding)) # difference (similarity calculation)# Siamese L1 Distance class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ca3b31c-6b01-41f6-b660-e978ba837d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 20:15:59.601392: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-05-27 20:15:59.601416: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-05-27 20:15:59.601420: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-05-27 20:15:59.601609: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-27 20:15:59.601625: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "siamese_model = load_model('siamesemodelv2.h5', custom_objects={'L1Dist': L1Dist, 'BinaryCrossentropy': tf.losses.BinaryCrossentropy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d8df078-9535-44e4-bee7-fb0d028ddd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually compile the model\n",
    "siamese_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc'), tf.keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2678af-971f-4fad-8873-104f8568c1f8",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c96ae539-3b06-41fe-afb4-e8b813534651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the image\n",
    "def preprocess(file_path):\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    img = tf.image.resize(img, (100, 100))\n",
    "    img = img / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bd14c9-7dc0-410c-b839-bb8cbbec6103",
   "metadata": {},
   "source": [
    "## Verify Function, Register Function and Writing Attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "050eaf15-8def-4135-862f-58db118d86f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify function\n",
    "def verify(model, input_img, verification_images_folder):\n",
    "    results = []\n",
    "    for person in os.listdir(verification_images_folder):\n",
    "        if person == '.DS_Store':\n",
    "            continue\n",
    "        person_folder = os.path.join(verification_images_folder, person)\n",
    "        for image in os.listdir(person_folder):\n",
    "            validation_img = preprocess(os.path.join(person_folder, image))\n",
    "            result = model.predict(list(tf.expand_dims([input_img, validation_img], axis=1)))\n",
    "            print(result, person)\n",
    "            results.append((result, person))\n",
    "    \n",
    "    detection_threshold = 0.5\n",
    "    detection = [res[0] > detection_threshold for res in results]\n",
    "    verification = np.sum(detection) / len(detection)\n",
    "    \n",
    "    if verification > 0.5:\n",
    "        return True, max(results, key=lambda x: x[0])[1]\n",
    "    else:\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89778867-1549-45f5-8cd7-7ffdba4945b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_event(person_name, event):\n",
    "    with open('siamese_application_data/attendance.csv', mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([person_name, event, datetime.now()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f7fd44d-70ea-4b4c-a039-f66c655bcf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_face(name):\n",
    "    user_dir = os.path.join('siamese_application_data', 'verification_images_app', name)\n",
    "    os.makedirs(user_dir, exist_ok=True)\n",
    "    \n",
    "    cap = cv2.VideoCapture(1)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    count = 0\n",
    "    \n",
    "    while count < 10:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            face_img = frame[y:y+h, x:x+w]\n",
    "            face_img = cv2.resize(face_img, (100, 100))\n",
    "            cv2.imwrite(os.path.join(user_dir, f'{name}_{count}.jpg'), face_img)\n",
    "            count += 1\n",
    "            if count >= 10:\n",
    "                break\n",
    "    \n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd17e2ff-3222-4a35-8e5d-7ef41d95c986",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## UI Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "947187ba-1f44-42b7-bec1-2bb094ba2d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_button(window, text, color, command, fg='white'):\n",
    "    button = Button(\n",
    "                        window,\n",
    "                        text=text,\n",
    "                        activebackground=\"black\",\n",
    "                        activeforeground=\"white\",\n",
    "                        fg=fg,\n",
    "                        bg=color,\n",
    "                        command=command,\n",
    "                        height=100,\n",
    "                        width=400,\n",
    "                        font=('Helvetica bold', 20)\n",
    "                    )\n",
    "    return button\n",
    "\n",
    "def get_img_label(window):\n",
    "    label = tk.Label(window)\n",
    "    label.grid(row=0, column=0)\n",
    "    return label\n",
    "\n",
    "def get_text_label(window, text):\n",
    "    label = tk.Label(window, text=text)\n",
    "    label.config(font=(\"sans-serif\", 21), justify=\"left\")\n",
    "    return label\n",
    "\n",
    "def get_entry_text(window):\n",
    "    inputtxt = tk.Text(window, height=2, width=15, font=(\"Arial\", 32))\n",
    "    return inputtxt\n",
    "\n",
    "def msg_box(title, description):\n",
    "    tk.messagebox.showinfo(title, description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224484a8-c108-4aa4-bdcf-306b922e3a4c",
   "metadata": {},
   "source": [
    "## Main App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0753d6bd-a344-4579-b7dc-3a7b01a7c01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 20:16:02.400 python[40812:1676622] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 20:23:32.771090: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.8004378]]] zun yang chin\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "[[[0.44579953]]] zun yang chin\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "[[[0.8631288]]] zun yang chin\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "[[[0.5825737]]] zun yang chin\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "[[[0.78071094]]] zun yang chin\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "[[[0.5974766]]] zun yang chin\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "[[[0.27138874]]] zun yang chin\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "[[[0.9577876]]] zun yang chin\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "[[[0.5291567]]] zun yang chin\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "[[[0.7243841]]] zun yang chin\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "[[[0.67922676]]] zun yang chin\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "[[[0.7584498]]] zun yang chin\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "[[[0.69112253]]] zun yang chin\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "[[[0.371997]]] zun yang chin\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "[[[0.55731946]]] zun yang chin\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "[[[0.51268965]]] zun yang chin\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "[[[0.60674435]]] zun yang chin\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "[[[0.8387663]]] zun yang chin\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "[[[0.53818625]]] zun yang chin\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "[[[0.38052154]]] zun yang chin\n"
     ]
    }
   ],
   "source": [
    "class App:\n",
    "    def __init__(self):\n",
    "        self.main_window = tk.Tk()\n",
    "        self.main_window.geometry(\"1200x520+350+100\")\n",
    "        self.main_window.title(\"Face Attendance System\")\n",
    "\n",
    "        self.text_label_register_new_user = get_text_label(self.main_window, 'Face Attendance System \\n by Zun Yang Chin')\n",
    "        self.text_label_register_new_user.place(x=750, y=70)\n",
    "\n",
    "        self.login_button_main_window = get_button(self.main_window, 'Login', 'green', self.login)\n",
    "        self.login_button_main_window.place(x=750, y=200)\n",
    "\n",
    "        self.logout_button_main_window = get_button(self.main_window, 'Logout', 'red', self.logout)\n",
    "        self.logout_button_main_window.place(x=750, y=300)\n",
    "\n",
    "        self.register_new_user_button_main_window = get_button(self.main_window, 'Register New User', 'blue', self.register_new_user)\n",
    "        self.register_new_user_button_main_window.place(x=750, y=400)\n",
    "\n",
    "        self.webcam_label = get_img_label(self.main_window)\n",
    "        self.webcam_label.place(x=10, y=0, width=700, height=500)\n",
    "\n",
    "        self.db_dir = './siamese_application_data/verification_images_app'\n",
    "        if not os.path.exists(self.db_dir):\n",
    "            os.mkdir(self.db_dir)\n",
    "\n",
    "        self.webcam_update_id = None\n",
    "        self.cap = cv2.VideoCapture(1)\n",
    "        self.add_webcam(self.webcam_label)\n",
    "\n",
    "        # Bind the close event to the main window\n",
    "        self.main_window.protocol(\"WM_DELETE_WINDOW\", self.on_closing)\n",
    "\n",
    "    def add_webcam(self, label):\n",
    "        self._label = label\n",
    "        self.process_webcam()\n",
    "\n",
    "    def process_webcam(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            return\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        self.box_color = (255, 0, 0)  # Always blue\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), self.box_color, 2)\n",
    "            self.most_recent_capture_arr = frame[y:y + h, x:x + w]\n",
    "\n",
    "        img_ = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        self.most_recent_capture_pil = Image.fromarray(img_)\n",
    "        self.imgtk = ImageTk.PhotoImage(image=self.most_recent_capture_pil)\n",
    "        self._label.imgtk = self.imgtk\n",
    "        self._label.configure(image=self.imgtk)\n",
    "\n",
    "        self.full_frame = frame  # Store the full frame\n",
    "\n",
    "        self.webcam_update_id = self._label.after(20, self.process_webcam)\n",
    "\n",
    "    def cancel_webcam_update(self):\n",
    "        if self.webcam_update_id:\n",
    "            self._label.after_cancel(self.webcam_update_id)\n",
    "            self.webcam_update_id = None\n",
    "\n",
    "    def login(self):\n",
    "        self.cancel_webcam_update()\n",
    "        input_img_path = 'siamese_application_data/input_image/input_image.jpg'\n",
    "        cv2.imwrite(input_img_path, self.most_recent_capture_arr)\n",
    "\n",
    "        # Perform anti-spoofing check with the full frame\n",
    "        label = test(\n",
    "            image=self.full_frame,\n",
    "            model_dir='/Users/zunyang/Library/CloudStorage/OneDrive-SwinburneUniversityOfTechnologySarawakCampus/Year2Sem2/AML/Face_Recognition_Project/antispoofing/resources/anti_spoof_models',\n",
    "            device_id=0\n",
    "        )\n",
    "\n",
    "        if label == 1:\n",
    "            input_img = preprocess(input_img_path)\n",
    "            last_verified, last_person_name = verify(siamese_model, input_img, self.db_dir)\n",
    "\n",
    "            if last_verified:\n",
    "                msg_box('Login Successfully!', 'Welcome, {}.'.format(last_person_name))\n",
    "                log_event(last_person_name, 'login')\n",
    "            else:\n",
    "                msg_box('Ups...', 'Unknown user. Please register new user or try again.')\n",
    "        else:\n",
    "            msg_box('You are fake!', 'Fake face detected. Try again.')\n",
    "\n",
    "        self.add_webcam(self.webcam_label)\n",
    "\n",
    "    def logout(self):\n",
    "        self.cancel_webcam_update()\n",
    "        input_img_path = 'siamese_application_data/input_image/input_image.jpg'\n",
    "        cv2.imwrite(input_img_path, self.most_recent_capture_arr)\n",
    "\n",
    "        # Perform anti-spoofing check with the full frame\n",
    "        label = test(\n",
    "            image=self.full_frame,\n",
    "            model_dir='/Users/zunyang/Library/CloudStorage/OneDrive-SwinburneUniversityOfTechnologySarawakCampus/Year2Sem2/AML/Face_Recognition_Project/antispoofing/resources/anti_spoof_models',\n",
    "            device_id=0\n",
    "        )\n",
    "\n",
    "        if label == 1:\n",
    "            input_img = preprocess(input_img_path)\n",
    "            last_verified, last_person_name = verify(siamese_model, input_img, self.db_dir)\n",
    "\n",
    "            if last_verified:\n",
    "                msg_box('Log Out Successfully!', 'Goodbye, {}.'.format(last_person_name))\n",
    "                log_event(last_person_name, 'logout')\n",
    "            else:\n",
    "                msg_box('Ups...', 'Unknown user. Please register new user or try again.')\n",
    "        else:\n",
    "            msg_box('You are fake!', 'Fake face detected. Try again.')\n",
    "\n",
    "        self.add_webcam(self.webcam_label)\n",
    "\n",
    "    def register_new_user(self):\n",
    "        self.cancel_webcam_update()\n",
    "        self.main_window.withdraw()  # Hide the main window\n",
    "\n",
    "        self.register_new_user_window = tk.Toplevel(self.main_window)  # Create a new Toplevel window for registration\n",
    "        self.register_new_user_window.geometry(\"1200x520+370+120\")\n",
    "        self.register_new_user_window.title(\"Register New User\")\n",
    "\n",
    "        self.register_button = get_button(self.register_new_user_window, 'Register', 'green', self.accept_register_new_user)\n",
    "        self.register_button.place(x=750, y=300)\n",
    "\n",
    "        self.cancel_button = get_button(self.register_new_user_window, 'Cancel', 'red', self.cancel_register)\n",
    "        self.cancel_button.place(x=750, y=400)\n",
    "\n",
    "        self.capture_label = get_img_label(self.register_new_user_window)\n",
    "        self.capture_label.place(x=10, y=0, width=700, height=500)\n",
    "\n",
    "        self.entry_text_register_new_user = get_entry_text(self.register_new_user_window)\n",
    "        self.entry_text_register_new_user.place(x=750, y=150)\n",
    "\n",
    "        self.text_label_register_new_user = get_text_label(self.register_new_user_window, 'Please, \\ninput username:')\n",
    "        self.text_label_register_new_user.place(x=750, y=70)\n",
    "\n",
    "        self.cap = cv2.VideoCapture(1)  # Reinitialize the camera\n",
    "        self.add_webcam(self.capture_label)\n",
    "\n",
    "        # Bind the close event to the register window\n",
    "        self.register_new_user_window.protocol(\"WM_DELETE_WINDOW\", self.cancel_register)\n",
    "\n",
    "    def accept_register_new_user(self):\n",
    "        name = self.entry_text_register_new_user.get(\"1.0\", \"end-1c\").strip()\n",
    "        if name:\n",
    "            self.register_button.config(state=tk.DISABLED)\n",
    "            self.cancel_button.config(state=tk.DISABLED)\n",
    "            self.entry_text_register_new_user.config(state=tk.DISABLED)\n",
    "            self.start_registration(name)\n",
    "        else:\n",
    "            msg_box('Error', 'Please enter a valid name.')\n",
    "\n",
    "    def cancel_register(self):\n",
    "        self.register_new_user_window.destroy()  # Destroy the registration window\n",
    "        self.cap.release()  # Release the camera\n",
    "        self.main_window.deiconify()  # Show the main window\n",
    "        self.cap = cv2.VideoCapture(1)  # Reinitialize the camera\n",
    "        self.add_webcam(self.webcam_label)  # Re-add the webcam to the main window\n",
    "\n",
    "    def start_registration(self, name):\n",
    "        person_folder = os.path.join(self.db_dir, name)\n",
    "        os.makedirs(person_folder, exist_ok=True)\n",
    "\n",
    "        count = 0\n",
    "        end_time = datetime.now() + timedelta(seconds=5)\n",
    "\n",
    "        def capture_frame():\n",
    "            nonlocal count\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                return\n",
    "\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                face_img = frame[y:y + h, x:x + w]\n",
    "\n",
    "                # Resize to 100x100\n",
    "                face_img = cv2.resize(face_img, (100, 100))\n",
    "\n",
    "                # Save the captured face\n",
    "                face_path = os.path.join(person_folder, f'{count + 1}.jpg')\n",
    "                cv2.imwrite(face_path, face_img)\n",
    "\n",
    "                count += 1\n",
    "\n",
    "            # Display countdown timer\n",
    "            remaining_time = end_time - datetime.now()\n",
    "            cv2.putText(frame, f'Remaining Time: {remaining_time.seconds}s', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "            cv2.imshow('Registration', frame)\n",
    "\n",
    "            if datetime.now() < end_time and count < 10:\n",
    "                self.register_new_user_window.after(500, capture_frame)\n",
    "            else:\n",
    "                cv2.destroyWindow('Registration')\n",
    "                msg_box('Success!', f'Registration complete for {name}.')\n",
    "                log_event(name, 'register')\n",
    "                \n",
    "                self.cancel_register()\n",
    "\n",
    "        capture_frame()\n",
    "\n",
    "    def on_closing(self):\n",
    "        self.cancel_webcam_update()\n",
    "        self.cap.release()\n",
    "        self.main_window.destroy()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def start(self):\n",
    "        self.main_window.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    app = App()\n",
    "    app.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816925a8-df4b-4e32-b88a-438272acec0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaa80a3-e217-485c-9442-331f8a427602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to clear the attendance.csv, and verification_images_app\n",
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# for root, dirs, files in os.walk('./siamese_application_data/verification_images_app'):\n",
    "#     for dir in dirs:\n",
    "#         shutil.rmtree(os.path.join(root, dir))\n",
    "\n",
    "\n",
    "\n",
    "# # opening the file with w+ mode truncates the file\n",
    "# f = open(\"siamese_application_data/attendance.csv\", \"w+\")\n",
    "# f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
